# Манифест по организации кодовой базы и форматированию Python‑кода для open-source проектов (2025)

## Введение

Этот документ описывает современные best practices для организации кодовой базы и форматирования Python‑кода в open-source проектах. Рекомендации направлены на повышение читаемости кода, удобство для генераторов кода на основе LLM (например, ChatGPT) и обеспечение контроля качества посредством ручной вычитки. Они опираются на официальные гайды (PEP 8, PEP 257, Packaging Guide), экспертов и практикующих разработчиков.

## 1. Форматирование кода

### 1.1 Стиль

Следовать PEP 8. Официальный стиль Python требует:

- Использовать отступы из 4 пробелов и избегать смешения пробелов/табуляции и лишних пробелов внутри скобок или перед запятыми[1].
- Располагать imports в начале файла после модульного docstring и «dunder»-переменных; группировать их: стандартная библиотека, затем сторонние пакеты, затем локальные модули, отделяя группы пустыми строками[2]. Не использовать `from module import *`, чтобы избежать загрязнения пространства имён[3].
- Использовать осмысленные имена: функции и переменные — `snake_case`; классы — `CamelCase`; константы — `ALL_CAPS`; модули — строчные имена с подчёркиваниями[4]. Имена должны быть описательными (например, `first_name` вместо `x`)[5].
- Расставлять вертикальные отступы для отделения классов/функций (две пустые строки) и логических блоков внутри сложных функций (одна строка)[6].
- Аннотации типов (PEP 484). Аннотируйте аргументы и возвращаемые значения с помощью синтаксиса `def func(arg: Type) -> ReturnType:`. В аннотациях вокруг стрелки `->` и равенства должны быть пробелы, а вокруг двоеточия пробел ставится только после типа[7]. Аннотации облегчают статический анализ и работу LLM, но не влияют на выполнение.
- Docstrings (PEP 257). Каждый модуль, класс, функция или метод должен иметь docstring. Однострочные docstrings — короткое описание, завершающееся точкой[8]. Многострочные docstrings начинаются с краткого резюме, затем пустая строка и подробности[9]. Используйте тройные двойные кавычки. Не дублируйте сигнатуру функции; описывайте только назначение и аргументы.
- Комментарии. Комментарии должны объяснять «почему», а не «как». Docstrings документируют интерфейсы, а комментарии — сложную логику; это различие подчёркивает Hitchhiker’s Guide[10].

### 1.2 Организация импортов

Используйте `isort` или аналогичный автоформаттер для сортировки импортов в группы (стандартная библиотека, третьи стороны, локальные). PEP 8 рекомендует именно такую группировку и избегание `import *`[11].

### 1.3 Именование и модульность

Называйте файлы и пакеты короткими и понятными именами. Пакеты обычно размещают в каталоге `src` для предотвращения случайного импорта тестируемого кода[12].

Разбейте код на небольшие модули. Каждая функция должна выполнять одну задачу; избегайте длинных (более ~50 строк) функций.

## 2. Автолинтеры и автоформаттеры

Автоматические инструменты помогают обеспечить единообразие кода и сокращают время ручной проверки.

### 2.1 Форматирование

- **Black** — «одностильный» форматтер: минимальная конфигурация, PEP 8‑совместимый стиль, контроль AST для безопасных изменений; форматирует код единообразно[13]. Используйте black для автоматического форматирования до коммита.
- **Ruff** — быстрый линтер и форматтер, поддерживающий множество проверок и автопочинок; для сортировки импортов требуется запустить `ruff check --select I --fix` до форматирования[14]. Ruff может заменить flake8 и pylint.
- **isort** — сортирует импорты по группам и алфавиту[15]; интеграцию с Black обеспечивает флаг `--profile black`.

### 2.2 Статический анализ

- **Ruff** или **flake8/pylint** — выполняют линтинг на уровне стиля, выявляют подозрительные конструкции. Ruff быстрее и поддерживает множество правил.
- **Mypy** — статический типизатор. Поскольку Python динамический, аннотации не изменяют поведение; mypy помогает обнаруживать ошибки типов без выполнения кода[16]. Интегрируйте его постепенно, используя `--disallow-untyped-defs` для строгости, как описано в руководстве[17].
- **Bandit** — SAST-анализатор, ищущий небезопасные шаблоны (использование `exec`/`eval`, слабые хэш-алгоритмы, hard-coded пароли, небезопасные вызовы `subprocess`, небезопасное использование `pickle`)[18]. Он лёгкий, поддерживает плагины и легко интегрируется в CI или pre-commit[19][20]. Следует учитывать, что Bandit может давать ложные срабатывания и не обнаруживает сложные логические ошибки; результаты требуют ручного анализа[21].

### 2.3 Управление хуками pre-commit

`pre-commit` — фреймворк для запуска линтеров и форматтеров при каждом коммите. Согласно документации, он помогает ловить простые ошибки до попадания кода в репозиторий, позволяя ревьюерам сосредоточиться на архитектуре, а не на стиле[22]. Конфигурация `.pre-commit-config.yaml` может содержать hooks для Black, Ruff, isort, mypy и Bandit. Хуки автоматически устанавливаются при `pre-commit install` и запускаются на изменённых файлах.

## 3. Обязательные проверки в CI

Непрерывная интеграция (CI) должна выполнять все проверки автоматически. GitHub Actions позволяет создавать workflow — YAML-файл, который определяет события (`push`, `pull_request`), jobs и steps[23].

### 3.1 Линтинг и типизация

- Линтеры: запуск `ruff check` и/или `flake8`/`pylint` в отдельном шаге CI. Пример workflow из статьи: установка зависимостей и запуск `flake8` и `pytest`[24].
- Типизация: `mypy --strict` (или `--disallow-untyped-defs`) чтобы выявлять проблемы типов.
- Сортировка импортов: запуск `isort --check` или `ruff check --select I --fix`.

### 3.2 Unit-тесты и тестовое покрытие

- **Pytest** — популярный фреймворк для тестирования. Директорию `tests/` располагают рядом с `src/` и именуют файлы `test_*.py` для автоматического обнаружения[25]. Альтернативно тесты можно хранить рядом с модулями[26].
- **Coverage** — измеряет процент строк кода, выполненных при тестах. Официальная документация поясняет, что coverage.py отслеживает, какие части программы были выполнены, и вычисляет «покрытие» для оценки эффективности тестов[27]. Командой `coverage run -m pytest` запускают тесты под контролем покрывающего инструмента, затем `coverage report --fail-under=85` для проверки процента, или `coverage html` для отчёта[28].

**Политика по покрытию.** Покрытие — метрический показатель, помогающий выявлять непроверённый код и сокращать технический долг: оно помогает находить ошибки, даёт уверенность в изменениях и документирует поведение программы[29]. Best practices: сосредотачиваться на критичных участках (не гнаться за 100%), регулярно анализировать непокрытый код и сочетать модульные и интеграционные тесты[30].

### 3.3 SAST и безопасность

- **Bandit** следует запускать в CI на pull request, чтобы находить уязвимости. Bandit является open-source и легко интегрируется[19][20].
- Дополнительные проверки: зависимые пакеты сканируют с помощью SCA-инструментов (например, `safety`, `pip-audit`). Лицензионные и лицензионные проверки также важно включать.

### 3.4 Интеграция с GitHub Actions

Пример workflow:

```
name: CI
on:
  pull_request:
  push:
    branches: [main]
jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.11, 3.12]
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
          pip install -e .[dev]  # установки из pyproject.toml
          pip install bandit coverage
      - name: Pre-commit
        run: pre-commit run --all-files
      - name: Run static analysis
        run: |
          ruff check .
          mypy --strict src/
          bandit -r src/
      - name: Run tests with coverage
        run: |
          coverage run -m pytest tests/
          coverage report --fail-under=85
```

Такой workflow устанавливает несколько версий Python, запускает pre-commit hooks, линтинги, проверку безопасности и тесты с покрытием, обеспечивая DevSecOps на каждом pull request[23][31].

## 4. Структура проекта

### 4.1 `src`-layout

Современные проекты размещают исходный код в каталоге `src/`, что предотвращает случайный импорт модулей из рабочей директории и заставляет устанавливать проект в режиме editable[12]. Структура обычно выглядит так:

```
project/
├── src/
│   └── my_package/
│       ├── __init__.py
│       ├── cli.py        # Командный интерфейс
│       ├── core.py       # Основная логика
│       ├── models/       # Сущности данных
│       ├── schemas/      # Схемы API/валидации
│       └── config/       # Конфигурации
├── tests/
│   ├── test_core.py
│   └── ...
├── docs/
├── pyproject.toml
├── README.md
└── LICENSE
```

`tests/`: размещайте все модульные тесты внутри `tests/`, следуя советам Pytest по именованию `test_*.py`[25]. Интеграционные тесты можно разделить.

`docs/`: документация, создаваемая Sphinx/MkDocs.

`data/schemas/`: схемы (pydantic, Marshmallow) разделяются в отдельную папку, чтобы не смешивать валидацию и бизнес-логику.

### 4.2 `pyproject.toml` и управление зависимостями

`pyproject.toml` заменил `setup.py` и `requirements.txt`. В нем три ключевых раздела: `[build-system]` для выбора backend и зависимостей сборки; `[project]` — метаданные проекта, включая зависимости, `optional-dependencies` и CLI-скрипты; `[tool]` — настройки инструментов (Black, Ruff, MyPy, coverage и др.)[32].

**Зависимости и extras.** В `[project.dependencies]` перечисляются основные зависимости; optional extras определяются в `[project.optional-dependencies]` (например, `dev` для инструментов разработки, `docs` для документации)[33]. CLI-скрипты регистрируются в `[project.scripts]`.

**Минимальные версии.** Определяйте `requires-python = ">=3.11"`, чтобы явно указать минимальную версию Python.

## 5. Документация

### 5.1 Docstrings и генерация API

Используйте Sphinx для генерации HTML/PDF документации. Sphinx импортирует код, извлекает docstrings и строит API-справочник[34].

Napoleon в Sphinx поддерживает Google и NumPy стили docstrings. Разделы `Args`, `Returns`, `Raises`, `Examples` превращаются в структурированный reStructuredText[35]. Наполеон поддерживает оба стиля; Google-стиль проще для коротких описаний, NumPy-стиль — для длинных документов[36]. Выберите один стиль и используйте его последовательно.

PEP 484 позволяет указывать типы в аннотациях вместо описаний типов в docstrings[37].

### 5.2 README и прочие файлы

`README.md` должен содержать краткое описание проекта, ссылку на сайт, информацию о лицензии и участниках; если необходимо, укажите инструкции по установке и примеру использования[38].

Обязательно включайте `LICENSE`. Для отслеживания изменений создайте файл `CHANGELOG.md` или раздел в README[39].

В корне проекта можно хранить `CONTRIBUTING.md` с правилами для новых участников.

### 5.3 Генерация и хостинг документации

Используйте `sphinx-quickstart` для создания скелета документации и `sphinx-autobuild` для live-режима.

Документацию можно размещать на Read the Docs; конфигурация описывается в `readthedocs.yml`.

## 6. Подход к ревью и комментированию LLM-генерируемого кода

LLM-инструменты ускоряют разработку, но повышают риск ошибок. По результатам исследований, до 30 % AI-сгенерированного кода содержит распространённые ошибки безопасности; поэтому каждую строку такого кода нужно рассматривать так же внимательно, как и вручную написанную[40].

### 6.1 Принципы ревью

- **Полноценный ручной анализ.** Начинайте ревью с понимания бизнес-логики и цели изменений; проверяйте, что код делает то, что требуется, и не нарушает другие части системы. Ищите отсутствие проверки входных данных, неправильную обработку ошибок, использование небезопасных API или утечку секретов[40].
- **Согласованность со стилем.** Автолинтеры должны быть выполнены до ревью. Проверяйте, что код соответствует архитектурным решениям и именованию; избегайте сложных функций и дублирования.
- **Сочетание автоматизированных средств.** Дополните ручной анализ статическими и динамическими инструментами (Bandit, mypy, тесты) и контролем зависимостей. В статье про SAST отмечается, что Bandit не обнаруживает сложные логические ошибки, поэтому только сочетание SAST и ревью обеспечивает безопасность[21].
- **Проверка зависимостей.** Доверяйте только известным библиотекам; используйте SCA-инструменты (`pip-audit`) для выявления уязвимостей и ведите список одобренных пакетов[41].
- **Безопасность подсказок и политика.** Разработчики должны формулировать промпты для LLM так, чтобы поощрять безопасные шаблоны. Организация может применять Policy-as-Code, чтобы блокировать непроверенный код на уровне CI/CD, и установить порог сложности — сложный код требует дополнительного ревью[42][43].

### 6.2 Комментирование и обратная связь

- **Фокус на поведении.** Делайте комментарии, основанные на поведении и целях функции, а не на личности автора (AI — это инструмент). Объясняйте, почему изменение важно и какой результат ожидается.
- **Предложение улучшений.** Если код сгенерирован LLM, помните, что модель может не знать контекст; предложите, как упростить реализацию или сделать её более идиоматичной для Python.
- **Документирование решений.** Сохраняйте обсуждения и принятые решения в pull-request, чтобы будущие разработчики могли понять мотивацию.

## Заключение

Приведённые рекомендации помогут построить читаемую, модульную и безопасную кодовую базу Python. Они учитывают требования людей и возможности LLM, но полагаются на ручную вычитку и тщательный контроль качества. Использование стандартизированной структуры, автолинтеров, статической и динамической проверки, тестов с покрытием и качественной документации обеспечивает высокую культуру разработки и упрощает привлечение новых участников в open-source проект.

